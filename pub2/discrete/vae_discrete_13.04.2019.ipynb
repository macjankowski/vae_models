{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropaget through mixture to find better betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from vae_lib.utils.dynamic_gmm_on_circle import DynamicGmmOnCircle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal = tf.distributions.Normal\n",
    "Bernoulli = tf.distributions.Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(X, y=None):\n",
    "    n_all_cases = X.shape[0]\n",
    "    perm = np.arange(n_all_cases)\n",
    "    np.random.shuffle(perm)\n",
    "    if y is not None:\n",
    "        return X[perm], y[perm]\n",
    "    else:\n",
    "        return X[perm], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, onehot_encoder, X, y):\n",
    "    m, sd = model.encode2(X)\n",
    "    m_flat = m.reshape(-1)\n",
    "    sd_flat = sd.reshape(-1)\n",
    "    y_decoded = onehot_encoder.inverse_transform(y).reshape(-1)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(m_flat, sd_flat, c=y_decoded, cmap='brg')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_latent_space(model, onehot_encoder, X, y):\n",
    "    m, sd = model_supervised.encode2(X_test)\n",
    "    y_decoded = onehot_encoder.inverse_transform(y_test).reshape(-1)\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(m[:,0], m[:,1], c=y_decoded, cmap='brg')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(sd[:,0], sd[:,1], c=y_decoded, cmap='brg')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.scatter(m[:,0], sd[:,0], c=y_decoded, cmap='brg')\n",
    "    plt.colorbar()\n",
    "\n",
    "    Z = np.random.normal(m,sd)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(Z[:,0], Z[:,1], c=y_decoded, cmap='brg')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train, X_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_all_cases = X.shape[0]\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (n_all_cases, -1))\n",
    "y = np.concatenate((y_train, y_test)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_reshaped = y.reshape(len(y), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "onehot_encoded = onehot_encoder.fit_transform(label_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = onehot_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_perm, onehot_encoded_perm = permute(X,onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_perm, onehot_encoded_perm, test_size=0.1, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_folder():\n",
    "    now = datetime.datetime.now()\n",
    "    day_of_the_year=now.strftime(\"%d_%m_%Y\")\n",
    "    suff = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    #print(now.strftime(\"%Y%m%d%H%M%S\"))\n",
    "    log_folder = \"/tmp/class_vae/deep/{}/{}\".format(day_of_the_year,suff)\n",
    "    return log_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_np(y_pred, y_true):\n",
    "    predicted_class = np.argmax(y_pred, axis=1)\n",
    "    true_class = np.argmax(y_true, axis=1)\n",
    "    cond_correct = predicted_class == true_class\n",
    "    return np.mean(cond_correct.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_for_score(y_pred, y_true, score, threshold):\n",
    "    cond = score > threshold\n",
    "    accuracy = calculate_accuracy_np(y_pred[cond], y_true[cond])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_ratio(score, threshold):\n",
    "    cond = score > threshold\n",
    "    above_threshold = np.mean((score > threshold).astype(int))\n",
    "    return above_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, f=tf.nn.relu, name=\"dense\"):\n",
    "        self.name = name\n",
    "        with tf.name_scope(self.name):\n",
    "            self.f = f\n",
    "            initializer = tf.contrib.layers.xavier_initializer()\n",
    "            self.W = tf.Variable(initializer((in_dim, out_dim)), name=\"W\")\n",
    "            self.b = tf.Variable(tf.constant(0.1, shape=[out_dim]), name=\"bias\")\n",
    "            tf.summary.histogram(\"weights\", self.W)\n",
    "            tf.summary.histogram(\"bias\", self.b)\n",
    "\n",
    "    def forward(self, X):\n",
    "        with tf.name_scope(self.name):\n",
    "            act = self.f(tf.matmul(X, self.W) + self.b)\n",
    "            tf.summary.histogram(\"activation\", act)\n",
    "            return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VClassifier:\n",
    "\n",
    "    def encode(self, X, middle_layer_dim):\n",
    "        current_value = X\n",
    "        for layer in self.encoder_layers:\n",
    "            current_value = layer.forward(current_value)\n",
    "\n",
    "        means = current_value[:, :middle_layer_dim]\n",
    "        tmp = current_value[:, middle_layer_dim:]\n",
    "#         stdevs = tf.sqrt(tf.exp(tmp))\n",
    "        stdevs = tf.nn.softplus(tmp) + 1e-6\n",
    "        \n",
    "        \n",
    "        return means, stdevs\n",
    "    \n",
    "    def create_encoder(self, X, input_dim, hidden_dims):\n",
    "        \n",
    "        in_dim = input_dim\n",
    "        for h_dim in hidden_dims[:-1]:\n",
    "            h = DenseLayer(in_dim, h_dim)\n",
    "            self.encoder_layers.append(h)\n",
    "            in_dim = h_dim\n",
    "\n",
    "        middle_layer_dim = hidden_dims[-1]\n",
    "        self.encoder_layers.append(DenseLayer(in_dim, 2 * middle_layer_dim, f=lambda x: x))\n",
    "\n",
    "        return self.encode(X, middle_layer_dim)\n",
    "    \n",
    "    def decode(self, Z, output_dim, hidden_dims):\n",
    "        decoder_layers = []\n",
    "\n",
    "        in_dim = hidden_dims[-1]\n",
    "        for hidden_dim in reversed(hidden_dims[:-1]):\n",
    "            h = DenseLayer(in_dim, hidden_dim)\n",
    "            decoder_layers.append(h)\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        decoder_layers.append(DenseLayer(in_dim, output_dim, f=lambda x: x))\n",
    "\n",
    "        current_value = Z\n",
    "        for decoder_layer in decoder_layers:\n",
    "            current_value = decoder_layer.forward(current_value)\n",
    "\n",
    "        return current_value\n",
    "    \n",
    "    def calculateKL(self, mean, std):\n",
    "        inner = 1 + tf.math.log(1e-8 + std ** 2) - mean ** 2 - std ** 2\n",
    "        kls = 0.5 * tf.math.reduce_sum(inner, axis=1)\n",
    "        return tf.math.reduce_mean(kls)\n",
    "    \n",
    "    def create_accuracy_node(self, y_true, y_pred):\n",
    "        correct_mask_node = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "        accuracy_node = tf.reduce_mean(tf.cast(correct_mask_node, tf.float32))\n",
    "        return accuracy_node\n",
    "\n",
    "    def __init__(self, x_dim, y_dim, hidden_dims, log_folder, alpha, beta, gamma, omega, r):\n",
    "        self.encoder_layers = []\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.layer = 1\n",
    "        self.cum_thetas = []\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, x_dim), name=\"x\")\n",
    "        self.y = tf.placeholder(tf.float32, shape=(None, y_dim), name=\"y\")\n",
    "        \n",
    "        init_cov = np.array([\n",
    "            [0.07,0.0],\n",
    "            [0.0,0.007]\n",
    "        ], dtype=\"float64\")\n",
    "        init_angles = [(2*i*np.pi)/10 for i in range(10)]\n",
    "        thetas = tf.get_variable(initializer=init_angles, name=\"thetas\")\n",
    "        tf.summary.histogram(\"thetas\", thetas)\n",
    "\n",
    "        self.d_gmm = DynamicGmmOnCircle(tf.unstack(thetas), init_cov, r=1)\n",
    "        \n",
    "        \n",
    "        #self.mix = MixtureOfNormalsOnCircle(10, r=r)\n",
    "\n",
    "        #encoder\n",
    "        self.means, self.stdevs = self.create_encoder(self.X, x_dim, hidden_dims)\n",
    "\n",
    "        n = Normal(\n",
    "          loc=self.means,\n",
    "          scale=self.stdevs,\n",
    "        )\n",
    "        self.Z = n.sample()\n",
    "\n",
    "        print(\"Hidden shape: {}\".format(self.Z.shape))\n",
    "\n",
    "        #decoder\n",
    "        self.logits = self.decode(self.Z, (x_dim+y_dim), hidden_dims)\n",
    "\n",
    "        self.XY_hat_distribution = Bernoulli(logits=self.logits)\n",
    "\n",
    "        self.posterior_predictive_probs = tf.nn.sigmoid(self.logits)\n",
    "        self.score = tf.norm(self.means, axis=1)\n",
    "        \n",
    "        if y_dim > 0:\n",
    "            self.posterior_predictive_probs_y = self.posterior_predictive_probs[:,x_dim:(x_dim+y_dim)]\n",
    "            print(\"self.posterior_predictive_probs_y.shape {}\".format(self.posterior_predictive_probs_y.get_shape().as_list()))\n",
    "            print(\"self.y.shape {}\".format(self.y.get_shape().as_list()))\n",
    "            self.accuracy_node = self.create_accuracy_node(self.y, self.posterior_predictive_probs_y)\n",
    "            tf.summary.scalar(\"accuracy\", self.accuracy_node)\n",
    "\n",
    "        with tf.name_scope('COST'):\n",
    "            \n",
    "            if y_dim > 0:\n",
    "                xy = tf.concat([self.X, self.y], axis=1)\n",
    "            else:\n",
    "                xy = self.X\n",
    "            print(\"xy.shape {}\".format(xy.get_shape().as_list()))\n",
    "\n",
    "            expected_log_likelihood_2 = -tf.reduce_sum(\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(labels=self.X, logits=self.logits[:,0:x_dim]), \n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            kl = self.calculateKL(self.means, self.stdevs)\n",
    "            tf.summary.scalar(\"KL\", kl)\n",
    "\n",
    "            gmm_cost = self.d_gmm.penalty_term_with_gd_only_tf(self.Z)\n",
    "#             gmm_cost = self.penalty_term_with_gd_only_tf(self.Z, tf.unstack(self.thetas), self.init_cov,r=1)\n",
    "#             gmm_cost = self.penalty_term_with_gd_only_tf(self.Z, tf.unstack(self.thetas), self.init_cov)\n",
    "            tf.summary.scalar(\"gmm_cost\", gmm_cost)\n",
    "            \n",
    "            exp_loglik_2 = tf.reduce_mean(expected_log_likelihood_2)\n",
    "            tf.summary.scalar(\"loglik_2\", exp_loglik_2)\n",
    "            \n",
    "            if y_dim > 0:\n",
    "                cross_entropy_classifier = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y, logits=self.logits[:,x_dim:(x_dim+y_dim)])\n",
    "                avg_cross_entropy_classifier = -tf.reduce_mean(cross_entropy_classifier)\n",
    "                tf.summary.scalar(\"softmax_cross_entropy\", avg_cross_entropy_classifier)\n",
    "                elbo = alpha * exp_loglik_2 + beta * kl + gamma * avg_cross_entropy_classifier - omega*gmm_cost\n",
    "            else:\n",
    "                elbo = alpha * exp_loglik_2 + beta * kl\n",
    "                \n",
    "            tf.summary.scalar(\"ELBO\", elbo)\n",
    "            \n",
    "        \n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(-elbo)\n",
    "        #self.train_op = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(-elbo)\n",
    "\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "        #InteractiveSession.close()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(self.init_op)\n",
    "\n",
    "        self.merged_summary = tf.summary.merge_all()\n",
    "\n",
    "        self.writer_train = tf.summary.FileWriter(log_folder)\n",
    "        self.writer_train.add_graph(self.sess.graph)\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=30, batch_sz=64):\n",
    "        #costs=[]\n",
    "        n_batches = len(X_train) // batch_sz\n",
    "        print(\"n_batches:\", n_batches)\n",
    "\n",
    "        \n",
    "        iteration = 1\n",
    "        for i in range(epochs):\n",
    "            print(\"epoch: %d\" % i)\n",
    "            #np.random.shuffle(X_train)\n",
    "            X_train, y_train = permute(X_train, y_train)\n",
    "            for j in range(n_batches):\n",
    "                batch_x = X_train[j * batch_sz:(j + 1) * batch_sz]\n",
    "                \n",
    "                if self.y_dim > 0:\n",
    "                    batch_y = y_train[j * batch_sz:(j + 1) * batch_sz]\n",
    "                    self.sess.run(self.train_op, feed_dict={self.X: batch_x, self.y: batch_y})\n",
    "                    if j % 100 == 0:\n",
    "                        s = self.sess.run(self.merged_summary, feed_dict={self.X: batch_x, self.y: batch_y})\n",
    "                        self.writer_train.add_summary(s, iteration)\n",
    "                        \n",
    "                        tf_thetas = self.sess.run(self.d_gmm.thetas, feed_dict={self.X: batch_x, self.y: batch_y})\n",
    "                        self.cum_thetas.append(tf_thetas)\n",
    "                else:\n",
    "                    self.sess.run(self.train_op, feed_dict={self.X: batch_x})\n",
    "                    if j % 100 == 0:\n",
    "                        s = self.sess.run(self.merged_summary, feed_dict={self.X: batch_x})\n",
    "                        self.writer_train.add_summary(s, iteration)\n",
    "                    \n",
    "                iteration += 1\n",
    "            \n",
    "            if self.y_dim > 0:\n",
    "                train_accuracy = self.calculate_accuracy(X_train, y_train)\n",
    "                print(\"Train accuracy {}\".format(train_accuracy))\n",
    "\n",
    "        # plt.plot(costs)\n",
    "        # plt.show()\n",
    "        \n",
    "    def calculate_accuracy(self, X, y):\n",
    "        accuracy = self.sess.run(self.accuracy_node, feed_dict={self.X: X, self.y: y})\n",
    "        return accuracy\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_pred = self.sess.run([self.posterior_predictive_probs_y, self.score], feed_dict={self.X: X})\n",
    "        return y_pred\n",
    "\n",
    "#     def predict_probs(self, X):\n",
    "#         return self.sess.run(self.posterior_predictive_probs, feed_dict={self.X: X})\n",
    "    \n",
    "    def encode2(self, X):\n",
    "        means, stdevs = self.sess.run([self.means, self.stdevs], feed_dict={self.X: X})\n",
    "        return means, stdevs\n",
    "    \n",
    "    def encode_to_discrete(self, X):\n",
    "        responsibilities = self.sess.run(self.resp, feed_dict={self.X: X})\n",
    "        return responsibilities\n",
    "    \n",
    "    def sampleLatent(self, X):\n",
    "        Z = self.sess.run(self.Z, feed_dict={self.X: X})\n",
    "        return Z\n",
    "    \n",
    "    def get_cum_thetas(self):\n",
    "        return self.cum_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting autoencoder. Log folder=/tmp/class_vae/deep/13_04_2019/20190413121434\n",
      "Hidden shape: (?, 2)\n",
      "self.posterior_predictive_probs_y.shape [None, 10]\n",
      "self.y.shape [None, 10]\n",
      "xy.shape [None, 794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/vae_tests/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_batches: 984\n",
      "epoch: 0\n"
     ]
    }
   ],
   "source": [
    "log_folder = get_log_folder()\n",
    "print('Starting autoencoder. Log folder={}'.format(log_folder))\n",
    "X_train, X_test, y_train, y_test\n",
    "model_supervised = VClassifier(\n",
    "    x_dim=X_train.shape[1], \n",
    "    y_dim=y_train.shape[1], \n",
    "    hidden_dims=[512, 256, 128, 2], \n",
    "    log_folder=log_folder,\n",
    "    alpha=0,\n",
    "    beta=0,\n",
    "    gamma=1,\n",
    "    omega=0.0005,\n",
    "    r=0.8\n",
    ")\n",
    "model_supervised.fit(X_train, y_train, epochs=3)\n",
    "\n",
    "test_acc = model_supervised.calculate_accuracy(X=X_test, y=y_test)\n",
    "print(\"Test accuracy {}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_2d_latent_space(model_supervised, onehot_encoder, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0009999952,\n",
       "  0.62731856,\n",
       "  1.2576371,\n",
       "  1.8859557,\n",
       "  2.5142741,\n",
       "  3.1425927,\n",
       "  3.7709112,\n",
       "  4.3992295,\n",
       "  5.0255485,\n",
       "  5.653867],\n",
       " [-0.00017283822,\n",
       "  0.6486639,\n",
       "  1.2773553,\n",
       "  1.914809,\n",
       "  2.5484147,\n",
       "  3.1196134,\n",
       "  3.7558312,\n",
       "  4.373508,\n",
       "  4.997271,\n",
       "  5.6288548],\n",
       " [0.028075336,\n",
       "  0.6647589,\n",
       "  1.2875576,\n",
       "  1.9569337,\n",
       "  2.5228608,\n",
       "  3.1150618,\n",
       "  3.7675376,\n",
       "  4.3599544,\n",
       "  4.9582624,\n",
       "  5.618497],\n",
       " [0.025343928,\n",
       "  0.6550565,\n",
       "  1.2820139,\n",
       "  1.9812785,\n",
       "  2.4984572,\n",
       "  3.1257105,\n",
       "  3.7870696,\n",
       "  4.365907,\n",
       "  4.9493494,\n",
       "  5.625228],\n",
       " [0.04803808,\n",
       "  0.6544715,\n",
       "  1.26527,\n",
       "  1.9860613,\n",
       "  2.4761667,\n",
       "  3.1383445,\n",
       "  3.7983468,\n",
       "  4.359501,\n",
       "  4.955674,\n",
       "  5.665645],\n",
       " [0.0633159,\n",
       "  0.6514347,\n",
       "  1.2340771,\n",
       "  1.9897064,\n",
       "  2.4768867,\n",
       "  3.149303,\n",
       "  3.8041236,\n",
       "  4.351792,\n",
       "  4.9642825,\n",
       "  5.6906815],\n",
       " [0.09943207,\n",
       "  0.64732105,\n",
       "  1.2018626,\n",
       "  1.9919826,\n",
       "  2.465067,\n",
       "  3.1643014,\n",
       "  3.8173144,\n",
       "  4.3485146,\n",
       "  4.9655747,\n",
       "  5.7186136],\n",
       " [0.1447727,\n",
       "  0.64569503,\n",
       "  1.1666875,\n",
       "  2.0040963,\n",
       "  2.4833877,\n",
       "  3.1785505,\n",
       "  3.8045106,\n",
       "  4.3534837,\n",
       "  4.9854126,\n",
       "  5.726617],\n",
       " [0.16348697,\n",
       "  0.6533521,\n",
       "  1.1455239,\n",
       "  2.0011892,\n",
       "  2.511473,\n",
       "  3.1875973,\n",
       "  3.8099773,\n",
       "  4.3574653,\n",
       "  4.9772673,\n",
       "  5.716331],\n",
       " [0.18226123,\n",
       "  0.6537328,\n",
       "  1.141231,\n",
       "  1.9935831,\n",
       "  2.5347247,\n",
       "  3.1892097,\n",
       "  3.7941797,\n",
       "  4.3380814,\n",
       "  4.981633,\n",
       "  5.7069855],\n",
       " [0.21076001,\n",
       "  0.6711339,\n",
       "  1.1533315,\n",
       "  1.9921414,\n",
       "  2.5449243,\n",
       "  3.1856651,\n",
       "  3.7899585,\n",
       "  4.3106394,\n",
       "  4.974179,\n",
       "  5.708962],\n",
       " [0.21524227,\n",
       "  0.6720128,\n",
       "  1.1667963,\n",
       "  1.9928706,\n",
       "  2.5580938,\n",
       "  3.1800244,\n",
       "  3.7934911,\n",
       "  4.3015814,\n",
       "  4.9769173,\n",
       "  5.70897],\n",
       " [0.2037521,\n",
       "  0.67892206,\n",
       "  1.1663791,\n",
       "  2.0076694,\n",
       "  2.56952,\n",
       "  3.1957312,\n",
       "  3.7875059,\n",
       "  4.2998595,\n",
       "  4.9639363,\n",
       "  5.714183],\n",
       " [0.21541134,\n",
       "  0.6831247,\n",
       "  1.1745324,\n",
       "  2.005217,\n",
       "  2.587544,\n",
       "  3.1926546,\n",
       "  3.7698655,\n",
       "  4.2972684,\n",
       "  4.9885736,\n",
       "  5.70789],\n",
       " [0.22118026,\n",
       "  0.68337834,\n",
       "  1.1722494,\n",
       "  2.0194068,\n",
       "  2.608125,\n",
       "  3.1979544,\n",
       "  3.763021,\n",
       "  4.2849603,\n",
       "  4.977854,\n",
       "  5.688],\n",
       " [0.22257112,\n",
       "  0.6970087,\n",
       "  1.1783048,\n",
       "  2.0200012,\n",
       "  2.614404,\n",
       "  3.2020526,\n",
       "  3.756657,\n",
       "  4.299428,\n",
       "  4.9518604,\n",
       "  5.690541],\n",
       " [0.22833554,\n",
       "  0.7038938,\n",
       "  1.1949816,\n",
       "  2.0306642,\n",
       "  2.6288362,\n",
       "  3.2065666,\n",
       "  3.7427118,\n",
       "  4.301705,\n",
       "  4.9334197,\n",
       "  5.6871967],\n",
       " [0.21611515,\n",
       "  0.6993423,\n",
       "  1.1960702,\n",
       "  2.0190213,\n",
       "  2.6374583,\n",
       "  3.2145076,\n",
       "  3.7515123,\n",
       "  4.2799363,\n",
       "  4.9459743,\n",
       "  5.6795425],\n",
       " [0.19118819,\n",
       "  0.6992448,\n",
       "  1.2091548,\n",
       "  2.026478,\n",
       "  2.6503868,\n",
       "  3.2308407,\n",
       "  3.756583,\n",
       "  4.269765,\n",
       "  4.9367557,\n",
       "  5.6790633],\n",
       " [0.1895841,\n",
       "  0.7061933,\n",
       "  1.1929256,\n",
       "  2.0132127,\n",
       "  2.6647422,\n",
       "  3.2318373,\n",
       "  3.7591295,\n",
       "  4.2810736,\n",
       "  4.9450235,\n",
       "  5.6846714],\n",
       " [0.19491231,\n",
       "  0.71951574,\n",
       "  1.1873615,\n",
       "  2.0263948,\n",
       "  2.6754754,\n",
       "  3.2306187,\n",
       "  3.7556016,\n",
       "  4.2872715,\n",
       "  4.929352,\n",
       "  5.6794586],\n",
       " [0.1787952,\n",
       "  0.7144605,\n",
       "  1.1843534,\n",
       "  2.033958,\n",
       "  2.6844633,\n",
       "  3.2485085,\n",
       "  3.7596147,\n",
       "  4.2854166,\n",
       "  4.9173336,\n",
       "  5.6576037],\n",
       " [0.17721754,\n",
       "  0.7132679,\n",
       "  1.1854216,\n",
       "  2.034618,\n",
       "  2.699866,\n",
       "  3.2497497,\n",
       "  3.759287,\n",
       "  4.2893414,\n",
       "  4.926341,\n",
       "  5.664647],\n",
       " [0.18894602,\n",
       "  0.71736956,\n",
       "  1.1911627,\n",
       "  2.0365808,\n",
       "  2.7191648,\n",
       "  3.2561364,\n",
       "  3.7525952,\n",
       "  4.2757187,\n",
       "  4.9123354,\n",
       "  5.6711426],\n",
       " [0.18552458,\n",
       "  0.727596,\n",
       "  1.19633,\n",
       "  2.0592115,\n",
       "  2.719761,\n",
       "  3.2514281,\n",
       "  3.757214,\n",
       "  4.2733665,\n",
       "  4.9061904,\n",
       "  5.6853366],\n",
       " [0.18275207,\n",
       "  0.7331944,\n",
       "  1.2036796,\n",
       "  2.0506108,\n",
       "  2.730175,\n",
       "  3.2456114,\n",
       "  3.7444773,\n",
       "  4.2677374,\n",
       "  4.9180293,\n",
       "  5.6700015],\n",
       " [0.18700701,\n",
       "  0.73941386,\n",
       "  1.2127041,\n",
       "  2.0503185,\n",
       "  2.752797,\n",
       "  3.2590377,\n",
       "  3.7302215,\n",
       "  4.282833,\n",
       "  4.938558,\n",
       "  5.655066],\n",
       " [0.18646264,\n",
       "  0.73882765,\n",
       "  1.2136111,\n",
       "  2.0384643,\n",
       "  2.7614028,\n",
       "  3.2660427,\n",
       "  3.7321103,\n",
       "  4.2743387,\n",
       "  4.9060864,\n",
       "  5.656613],\n",
       " [0.17963879,\n",
       "  0.7526391,\n",
       "  1.2304054,\n",
       "  2.0218396,\n",
       "  2.794851,\n",
       "  3.287711,\n",
       "  3.7329164,\n",
       "  4.2768116,\n",
       "  4.917347,\n",
       "  5.6377234],\n",
       " [0.16877285,\n",
       "  0.7549618,\n",
       "  1.2306768,\n",
       "  2.0115056,\n",
       "  2.8339877,\n",
       "  3.2913153,\n",
       "  3.7562897,\n",
       "  4.281518,\n",
       "  4.8993683,\n",
       "  5.63231]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_supervised.get_cum_thetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_train = model_supervised.encode_to_discrete(X_train)\n",
    "resp_test = model_supervised.encode_to_discrete(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63000, 10), (7000, 10), (63000, 784))"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_train.shape, resp_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_train = model_supervised.sampleLatent(X_train)\n",
    "latent_test = model_supervised.sampleLatent(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63000, 2)"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    \n",
    "    def __init__(self, dims):\n",
    "        self.dims = dims\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, [None, dims[0]])\n",
    "        self.y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#         l1 = DenseLayer(dims[0], dims[1])\n",
    "#         l2 = DenseLayer(dims[1], 10, f=lambda x: x)\n",
    "#         tmp = l1.forward(self.x)\n",
    "#         y_pred = l2.forward(tmp)\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        in_dim = dims.pop(0)\n",
    "        for h_dim in dims:\n",
    "            h = DenseLayer(in_dim, h_dim)\n",
    "            layers.append(h)\n",
    "            in_dim = h_dim\n",
    "\n",
    "        current_value = self.x\n",
    "        for layer in layers:\n",
    "            current_value = layer.forward(current_value)\n",
    "        \n",
    "        y_pred = current_value\n",
    "\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_pred, labels=self.y_true))\n",
    "#         self.gd_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "        self.gd_step = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cross_entropy)\n",
    "        \n",
    "        correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(self.y_true, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n",
    "    \n",
    "    def fit(self, train_input, train_output, test_input, test_output, epochs=10):\n",
    "        \n",
    "        n_batches = len(train_input) // self.batch_size\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for i in range(epochs):\n",
    "                for j in range(n_batches):\n",
    "                    batch_x = train_input[j * self.batch_size:(j + 1) * self.batch_size]\n",
    "                    batch_y = train_output[j * self.batch_size:(j + 1) * self.batch_size]\n",
    "                    sess.run(self.gd_step, feed_dict={self.x: batch_x, self.y_true: batch_y})\n",
    "\n",
    "            train_accuracy = sess.run(self.accuracy, feed_dict={self.x: train_input, self.y_true: train_output})\n",
    "            test_accuracy = sess.run(self.accuracy, feed_dict={self.x: test_input, self.y_true: test_output})\n",
    "            print(\"Train accuracy: {:.4}%\".format(train_accuracy*100))\n",
    "            print(\"Test accuracy: {:.4}%\".format(test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_nn = SimpleNN([784,512,10])\n",
    "# simple_nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 86.57%\n",
      "Test accuracy: 85.49%\n"
     ]
    }
   ],
   "source": [
    "simple_nn = SimpleNN([10,512, 256, 128, 10])\n",
    "simple_nn.fit(resp_train, y_train, resp_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 66.89%\n",
      "Test accuracy: 66.24%\n"
     ]
    }
   ],
   "source": [
    "simple_nn = SimpleNN([2,512, 256, 128, 10])\n",
    "simple_nn.fit(latent_train, y_train, latent_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63000, 10)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(resp_train).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(resp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_train[34097,:] = np.zeros(10)\n",
    "resp_train[40214,:] = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "clf.fit(resp_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predict = clf.predict(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6604285714285715"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy_np(y_pred=rf_predict, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(resp_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 3, ..., 3, 1, 2])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = pd.DataFrame({\n",
    "    'in': np.argmax(resp_train, axis=1),\n",
    "    'out': np.argmax(y_train, axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = reduced_data[reduced_data['in']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       in\n",
       "out      \n",
       "1       1\n",
       "2       3\n",
       "3      13\n",
       "4     468\n",
       "5      12\n",
       "6       6\n",
       "7      50\n",
       "8      22\n",
       "9    5912"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.groupby(['out']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
